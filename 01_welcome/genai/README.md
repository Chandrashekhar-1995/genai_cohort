## Day 1

- Reading material
    -    link tiktokenizer.vercel.app
    -   every vord have a diffrent token (token == word dixanory)
    -   attention all you need google -  https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf
    -   for vector invading
    -   https://projector.tensorflow.org/

-   install
    -   pip install tiktoken
    -   pip install openai
    -   pip install python-dotenv

-   Day 1 Assignment
    -   write article on hashnode subject- DECODING AI JARGONS WITH CHAI
        - Topics covered-
            - transformers
            - encoder
            - decoder
            - vectors
            - embeddings
            - possitional encoding
            - semantic meaning
            - self attention
            - softmax
            - multi head attention
            - temp
            - knowledge cutoff
            - tokenizations
            - vocab size
    -   Write your own tokenizer from scretch support 2 lang- Hindi & English
            calass Encoder
            encode
            decode

